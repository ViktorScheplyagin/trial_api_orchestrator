| Provider                          | Core API Methods                                                                                                                                                                                         | Free-Tier Quotas                                                                                                                                                                                                      | Reset Policy                                                                         | Notes                                                                                          |
| --------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------- |
| **Gemini API (Google AI Studio)** | • `POST {model}:generateContent`<br>• `POST {model}:streamGenerateContent`<br>• `GET /v1/models`<br>• `POST /v1beta/models/{model}:countTokens`<br>• `POST /v1beta/models/{embeddingModel}:embedContent` | Example free-tier (text-out):<br>• Gemini 2.5 Pro → 5 RPM, 250k TPM, 100 RPD<br>• Gemini 2.5 Flash → 10 RPM, 250k TPM, 250 RPD<br>• Gemma 3n → 30 RPM, 15k TPM, 14,400 RPD<br>Embeddings: 100 RPM, 30k TPM, 1,000 RPD | • RPM/TPM reset every minute<br>• RPD reset daily at midnight PT                     | Very detailed quota tables, transparent limits. Auth via API key (`x-goog-api-key`). Gemini chat adapter implemented in orchestrator v1.           |
| **Cerebras Inference API**        | • `POST /api/chat/completions`<br>• `POST /api/completions`<br>• `GET /api/models`                                                                                                                       | Free-tier example: ~30 RPM, 64k tokens/min, 1M tokens/day                                                                                                                                                             | • Per-minute and per-day reset<br>• Actual usage visible via `x-ratelimit-*` headers | Strong OpenAI-compatible design, returns rate-limit headers so you can track programmatically. |
| **OpenRouter**                    | • `POST /api/v1/chat/completions`<br>• `GET /api/v1/models`                                                                                                                                              | Free models: 20 RPM, 50 RPD<br>(boosted to 1000 RPD if ≥10 credits purchased)                                                                                                                                         | • RPM reset per minute<br>• RPD reset daily                                          | Unified gateway to multiple providers; very close to OpenAI format. OpenRouter adapter implemented in orchestrator v1. |
| **Cohere**                        | • `POST /v2/chat`<br>• `POST /v2/embed`<br>• `POST /v2/rerank`<br>• `POST /v2/tokenize`                                                                                                                  | Historically: 1000 calls/month with trial key. In dashboard may show “Unlimited”, but subject to hidden fair-use limits.                                                                                              | • Per-minute caps (e.g. 20 RPM chat, 100 RPM embed)<br>• Monthly quotas              | SDK-first approach (Python/JS clients). Auth via API key. Cohere chat adapter implemented in orchestrator v1. |
| **DeepSeek**                      | • `POST /completions`<br>• `GET /models`                                                                                                                                                                 | ❌ No free-tier (paid only)                                                                                                                                                                                            | —                                                                                    | API is OpenAI-compatible, easy migration path. Requires paid key.                              |



---

### Commentary / Caveats & Practical Notes

* Look [here](./providers_api_docs.md) the detailed documentation of all the providers API
* For **Cerebras**, they provide **rate-limit headers** (`x-ratelimit-*`) in each API response, so you can **programmatically see how much you have remaining** until the daily or per-minute quota resets.
* For **OpenRouter**, the limits are quite explicit for the free variant (20/min, 50/day or 1000/day depending on credit purchase).
* For **Gemini**, the free-tier rate limits are somewhat opaque in official docs, but the API documentation states the reset rules (RPD resets at midnight PT), and many user reports and blog sources mention the 5 RPM limit.
* For **Mistral**, the free tier is described as “restrictive,” and they delineate the types of quotas (RPS, minute tokens, monthly tokens), but they don’t publish exact numbers for all tiers in the section I found.
* For **Cohere**, their docs do list explicit trial key limits (1000 calls/month) and per-minute limits for specific endpoints.
* For **Groq** and **Together AI**, I could not locate official, up-to-date documentation on their free-tier quotas in my search. It might exist internally or behind account dashboards.
